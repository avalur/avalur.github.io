{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/nup_logo_dark.jpeg\" width=300 style=\"display: inline-block;\"></center>\n",
    "\n",
    "## Advanced ML\n",
    "### Topic modeling and word2vec\n",
    "\n",
    "<br />\n",
    "April 8, 2025\n",
    "\n",
    "\n",
    "This notebook examines two topic modeling models from the `gensim` library:\n",
    "  - LDA (Latent Dirichlet Allocation)\n",
    "  - word2vec\n",
    "\n",
    "Sources of inspiration:\n",
    "  - https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "  - https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0fw1oPDs6wY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LDA (Latent Dirichlet Allocation)\n",
    "We install the topic modeling library gensim (http://radimrehurek.com/gensim/) and load the NLTK library (http://nltk.org/), which will be needed for lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "end_time": "2025-04-01T10:59:53.018609Z",
     "start_time": "2025-04-01T10:59:49.083501Z"
    }
   },
   "source": [
    "!pip install --upgrade gensim\n",
    "!pip install --upgrade nltk"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (4.3.3)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from gensim) (1.26.4)\r\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from gensim) (1.13.1)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from gensim) (7.1.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: nltk in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: click in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /Users/Aleksandr.Avdiushenko/IdeaProjects/avalur.github.io/.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gdyoxngvyleT",
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "end_time": "2025-04-01T11:00:02.879835Z",
     "start_time": "2025-04-01T10:59:59.508639Z"
    }
   },
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from math import log\n",
    "from time import time\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MBeC_QT3wz3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We read the collection of source texts into a list of documents. Each document is a list of lemmas (tokens). In this example, we load the entire collection into memory. In fact, `gensim` allows you to avoid this at all stages of model building.\n",
    "\n",
    "The collection used is articles from the NeurIPS conference, one of the standard collections for topic modeling. The number of documents is about 1700, with each document having a length of 1000-2000 words. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNi0iXA-1WS1",
    "outputId": "cf89826a-16a6-4100-fd10-4c10151eb683",
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:04.225900Z",
     "start_time": "2025-04-01T11:01:04.222990Z"
    }
   },
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request, zipfile\n",
    "\n",
    "\n",
    "tarfile_url = 'https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'\n",
    "filename = 'nips12raw_str602.tgz'\n",
    "# urllib.request.urlretrieve(tarfile_url, filename)\n",
    "\n",
    "def extract_documents(fname=filename):\n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        # Ignore directory entries, as well as files like README, etc.\n",
    "        files = [\n",
    "            m for m in tar.getmembers()\n",
    "            if m.isfile() and re.search(r'nipstxt/nips\\d+/\\d+\\.txt', m.name)\n",
    "        ]\n",
    "        for member in sorted(files, key=lambda x: x.name):\n",
    "            member_bytes = tar.extractfile(member).read()\n",
    "            yield member_bytes.decode('utf-8', errors='replace')\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:08.210649Z",
     "start_time": "2025-04-01T11:01:07.484274Z"
    }
   },
   "source": [
    "docs = list(extract_documents())\n",
    "print(len(docs))\n",
    "print(print(docs[0][:500]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "1 \n",
      "CONNECTIVITY VERSUS ENTROPY \n",
      "Yaser S. Abu-Mostafa \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "ABSTRACT \n",
      "How does the connectivity of a neural network (number of synapses per \n",
      "neuron) relate to the complexity of the problems it can handle (measured by \n",
      "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
      "functions can be implemented using a circuit with very low connectivity (e.g., \n",
      "using two-input NAND gates). However, for a network that learns a pr\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1jWGQ6143kc"
   },
   "source": [
    "Data preparation:\n",
    "- Create a dictionary\n",
    "- Perform lemmatization\n",
    "- Build n-grams\n",
    "- Filter out tokens that are too frequent or too rare"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BPPS5jSN4Fy9",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:21.141936Z",
     "start_time": "2025-04-01T11:01:20.511735Z"
    }
   },
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words."
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-kzrHz65gQh",
    "outputId": "fbb1e8cf-3b42-4c95-f75c-deef3efad1d0",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:22.235843Z",
     "start_time": "2025-04-01T11:01:22.117133Z"
    }
   },
   "source": [
    "print(np.sum([len(doc) for doc in docs]))\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "print(np.sum([len(doc) for doc in docs]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5461201\n",
      "5115888\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:30.266409Z",
     "start_time": "2025-04-01T11:01:30.264366Z"
    }
   },
   "source": [
    "print(docs[1][:50])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stochastic', 'learning', 'networks', 'and', 'their', 'electronic', 'implementation', 'joshua', 'alspector', 'robert', 'b', 'allen', 'victor', 'hut', 'and', 'srinagesh', 'satyanarayana', 'bell', 'communications', 'research', 'morristown', 'nj', 'abstract', 'we', 'describe', 'a', 'family', 'of', 'learning', 'algorithms', 'that', 'operate', 'on', 'a', 'recurrent', 'symmetrically', 'connected', 'neuromorphic', 'network', 'that', 'like', 'the', 'boltzmann', 'machine', 'settles', 'in', 'the', 'presence', 'of', 'noise']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQkmqQQ97bIj",
    "outputId": "65967b8f-6af2-462f-b550-525e07f82452",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:33.455910Z",
     "start_time": "2025-04-01T11:01:33.284892Z"
    }
   },
   "source": [
    "# Remove words that are only one character\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "print(np.sum([len(doc) for doc in docs]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4629808\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSjycOUfGhCw",
    "outputId": "7f6d019c-6f18-4cf3-c6ae-d91cbf923185",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:45.663982Z",
     "start_time": "2025-04-01T11:01:45.523777Z"
    }
   },
   "source": [
    "# Remove words with underscores, since we are going to use them as delimiters in bigrams\n",
    "docs = [[token for token in doc if '_' not in token] for doc in docs]\n",
    "print(np.sum([len(doc) for doc in docs]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4626035\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HUBuhfJNERyR",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:51.002311Z",
     "start_time": "2025-04-01T11:01:50.755543Z"
    }
   },
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Aleksandr.Avdiushenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtGLu8yaEkvU",
    "outputId": "77dca455-dd2a-4cbe-f17b-4a5759feaa57",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:01:55.114567Z",
     "start_time": "2025-04-01T11:01:54.077524Z"
    }
   },
   "source": [
    "print(lemmatizer.lemmatize('abstracts'),\n",
    "      lemmatizer.lemmatize('fishes'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract fish\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fCkF1Hqm50BK",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:02.402753Z",
     "start_time": "2025-04-01T11:01:56.254146Z"
    }
   },
   "source": [
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdyb94Br6OZh",
    "outputId": "792d541f-af70-45a3-bcc5-4e37b99add50",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:05.816295Z",
     "start_time": "2025-04-01T11:02:03.503397Z"
    }
   },
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:02:03,504 : INFO : collecting all words and their counts\n",
      "2025-04-01 14:02:03,505 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-04-01 14:02:05,814 : INFO : collected 1114271 token types (unigram + bigrams) from a corpus of 4626035 words and 1740 sentences\n",
      "2025-04-01 14:02:05,815 : INFO : merged Phrases<1114271 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n",
      "2025-04-01 14:02:05,815 : INFO : Phrases lifecycle event {'msg': 'built Phrases<1114271 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 2.31s', 'datetime': '2025-04-01T14:02:05.815245', 'gensim': '4.3.3', 'python': '3.12.6 (v3.12.6:a4a2d2b0d85, Sep  6 2024, 16:08:03) [Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-15.3.2-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iT1DIBdvG3jq",
    "outputId": "ce101124-b0c0-49b7-e295-ae4ba21c8ac7",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:09.233493Z",
     "start_time": "2025-04-01T11:02:09.231321Z"
    }
   },
   "source": [
    "for token in bigram[docs[0][:100]]:\n",
    "    if '_' in token:\n",
    "        print(token)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abu_mostafa\n",
      "california_institute\n",
      "technology_pasadena\n",
      "ca_abstract\n",
      "neural_network\n",
      "boolean_function\n",
      "can_be\n",
      "very_low\n",
      "learning_rule\n",
      "lower_bound\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBnDw_SwHJvv",
    "outputId": "668b3088-fd02-470c-b612-20b7f277664c",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:16.755014Z",
     "start_time": "2025-04-01T11:02:13.912085Z"
    }
   },
   "source": [
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document\n",
    "            docs[idx].append(token)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:19.120949Z",
     "start_time": "2025-04-01T11:02:18.185209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(docs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:02:18,185 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2025-04-01 14:02:19,119 : INFO : built Dictionary<77939 unique tokens: ['0a', '2h', '2h2', '2he', '2n']...> from 1740 documents (total 4944995 corpus positions)\n",
      "2025-04-01 14:02:19,119 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<77939 unique tokens: ['0a', '2h', '2h2', '2he', '2n']...> from 1740 documents (total 4944995 corpus positions)\", 'datetime': '2025-04-01T14:02:19.119792', 'gensim': '4.3.3', 'python': '3.12.6 (v3.12.6:a4a2d2b0d85, Sep  6 2024, 16:08:03) [Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-15.3.2-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Remove words that are too rare (e.g., typos) and words that are too frequent (e.g., stop words or just common non-topic terms). The `filter_extremes` function removes tokens from the dictionary that appear in less than `no_below` documents or in more than `no_above` fraction of the total number of documents."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:27.863324Z",
     "start_time": "2025-04-01T11:02:27.795889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove rare and common tokens\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:02:27,849 : INFO : discarding 69316 tokens: [('0a', 19), ('2h', 16), ('2h2', 1), ('2he', 3), ('a', 1740), ('about', 1058), ('abstract', 1740), ('after', 1087), ('alently', 2), ('all', 1658)]...\n",
      "2025-04-01 14:02:27,849 : INFO : keeping 8623 tokens which were in no less than 20 and no more than 870 (=50.0%) documents\n",
      "2025-04-01 14:02:27,860 : INFO : resulting dictionary: Dictionary<8623 unique tokens: ['2n', 'a2', 'a_follows', 'ability', 'abu']...>\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Represent all documents in vector form (Bag-of-Words)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GH6NNGAKH5OD",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:39.617991Z",
     "start_time": "2025-04-01T11:02:39.031967Z"
    }
   },
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2yKG6JJ9Ili4",
    "outputId": "fc7dab88-81ef-4cc9-e96e-921fa7499252",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:41.441362Z",
     "start_time": "2025-04-01T11:02:41.439290Z"
    }
   },
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 8623\n",
      "Number of documents: 1740\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:02:43.483858Z",
     "start_time": "2025-04-01T11:02:43.481894Z"
    }
   },
   "cell_type": "code",
   "source": "print(corpus[0][:10])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (1, 1), (2, 1), (3, 2), (4, 4), (5, 4), (6, 1), (7, 1), (8, 1), (9, 1)]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGMtwCDqxg8N"
   },
   "source": [
    "### Training\n",
    "Now we are ready to build a topic model for our collection. We will build an online LDA model, implemented in the `gensim` library. We specify the vectorized corpus of texts, the dictionary, and the number of topics (10). We will discuss the remaining parameters later."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGrywSb9MvMK",
    "outputId": "cc0be619-05ae-46ca-8546-77cee2305076",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:12.347434Z",
     "start_time": "2025-04-01T11:02:56.900551Z"
    }
   },
   "source": [
    "start = time()\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000  # batch-size\n",
    "epochs = 5   \n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=epochs,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "print('Evaluation time: {}'.format((time()-start) / 60))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:02:56,902 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "2025-04-01 14:02:56,903 : INFO : using serial LDA version on this node\n",
      "2025-04-01 14:02:56,908 : INFO : running online (multi-pass) LDA training, 10 topics, 5 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2025-04-01 14:02:56,908 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2025-04-01 14:02:56,908 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2025-04-01 14:03:02,186 : INFO : optimized alpha [0.058868334, 0.074743286, 0.06977449, 0.1018687, 0.086200245, 0.076768756, 0.06202958, 0.045915615, 0.10657893, 0.06756638]\n",
      "2025-04-01 14:03:02,189 : INFO : topic #7 (0.046): 0.004*\"tree\" + 0.004*\"node\" + 0.003*\"matrix\" + 0.003*\"cell\" + 0.003*\"image\" + 0.003*\"neuron\" + 0.003*\"graph\" + 0.003*\"connection\" + 0.003*\"distance\" + 0.002*\"field\"\n",
      "2025-04-01 14:03:02,190 : INFO : topic #0 (0.059): 0.010*\"neuron\" + 0.003*\"layer\" + 0.003*\"node\" + 0.003*\"solution\" + 0.003*\"signal\" + 0.003*\"class\" + 0.003*\"cell\" + 0.003*\"net\" + 0.002*\"classifier\" + 0.002*\"hidden\"\n",
      "2025-04-01 14:03:02,190 : INFO : topic #4 (0.086): 0.005*\"cell\" + 0.005*\"image\" + 0.004*\"field\" + 0.004*\"hidden\" + 0.004*\"layer\" + 0.003*\"memory\" + 0.003*\"stimulus\" + 0.002*\"recognition\" + 0.002*\"response\" + 0.002*\"activity\"\n",
      "2025-04-01 14:03:02,190 : INFO : topic #3 (0.102): 0.005*\"neuron\" + 0.003*\"class\" + 0.003*\"control\" + 0.003*\"image\" + 0.003*\"layer\" + 0.003*\"signal\" + 0.003*\"noise\" + 0.003*\"dynamic\" + 0.002*\"sequence\" + 0.002*\"approximation\"\n",
      "2025-04-01 14:03:02,191 : INFO : topic #8 (0.107): 0.005*\"layer\" + 0.004*\"neuron\" + 0.004*\"signal\" + 0.003*\"image\" + 0.003*\"hidden\" + 0.003*\"noise\" + 0.003*\"rule\" + 0.003*\"component\" + 0.003*\"response\" + 0.003*\"class\"\n",
      "2025-04-01 14:03:02,191 : INFO : topic diff=1.186335, rho=1.000000\n",
      "2025-04-01 14:03:02,194 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2025-04-01 14:03:05,601 : INFO : optimized alpha [0.048630204, 0.06215061, 0.056516502, 0.07723892, 0.06686515, 0.06625134, 0.05423925, 0.03981673, 0.08167267, 0.056728445]\n",
      "2025-04-01 14:03:05,604 : INFO : topic #7 (0.040): 0.005*\"node\" + 0.005*\"tree\" + 0.004*\"graph\" + 0.004*\"distance\" + 0.003*\"tangent\" + 0.003*\"matrix\" + 0.003*\"image\" + 0.003*\"action\" + 0.003*\"robot\" + 0.003*\"mapping\"\n",
      "2025-04-01 14:03:05,605 : INFO : topic #0 (0.049): 0.009*\"neuron\" + 0.005*\"action\" + 0.005*\"policy\" + 0.003*\"solution\" + 0.003*\"node\" + 0.003*\"optimal\" + 0.003*\"classifier\" + 0.003*\"layer\" + 0.003*\"reward\" + 0.002*\"cost\"\n",
      "2025-04-01 14:03:05,605 : INFO : topic #4 (0.067): 0.006*\"cell\" + 0.006*\"field\" + 0.005*\"image\" + 0.004*\"layer\" + 0.004*\"stimulus\" + 0.004*\"memory\" + 0.003*\"response\" + 0.003*\"visual\" + 0.003*\"hidden\" + 0.003*\"activity\"\n",
      "2025-04-01 14:03:05,606 : INFO : topic #3 (0.077): 0.003*\"neuron\" + 0.003*\"class\" + 0.003*\"control\" + 0.003*\"approximation\" + 0.003*\"density\" + 0.003*\"sequence\" + 0.003*\"sample\" + 0.003*\"dynamic\" + 0.003*\"matrix\" + 0.003*\"gaussian\"\n",
      "2025-04-01 14:03:05,606 : INFO : topic #8 (0.082): 0.005*\"layer\" + 0.004*\"signal\" + 0.004*\"speech\" + 0.004*\"image\" + 0.004*\"hidden\" + 0.004*\"noise\" + 0.003*\"component\" + 0.003*\"neuron\" + 0.003*\"recognition\" + 0.003*\"class\"\n",
      "2025-04-01 14:03:05,606 : INFO : topic diff=0.287336, rho=0.577350\n",
      "2025-04-01 14:03:05,610 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2025-04-01 14:03:08,104 : INFO : optimized alpha [0.042827006, 0.05581211, 0.049770437, 0.06607363, 0.056949854, 0.06083446, 0.050607473, 0.036612723, 0.06898753, 0.051134758]\n",
      "2025-04-01 14:03:08,108 : INFO : topic #7 (0.037): 0.006*\"node\" + 0.006*\"distance\" + 0.005*\"graph\" + 0.005*\"tree\" + 0.004*\"robot\" + 0.004*\"tangent\" + 0.003*\"matrix\" + 0.003*\"mapping\" + 0.003*\"image\" + 0.003*\"action\"\n",
      "2025-04-01 14:03:08,108 : INFO : topic #0 (0.043): 0.008*\"action\" + 0.008*\"policy\" + 0.006*\"neuron\" + 0.004*\"reward\" + 0.004*\"reinforcement\" + 0.004*\"optimal\" + 0.003*\"reinforcement_learning\" + 0.003*\"solution\" + 0.003*\"decision\" + 0.003*\"cost\"\n",
      "2025-04-01 14:03:08,108 : INFO : topic #5 (0.061): 0.015*\"neuron\" + 0.011*\"cell\" + 0.005*\"circuit\" + 0.005*\"signal\" + 0.005*\"response\" + 0.005*\"frequency\" + 0.004*\"chip\" + 0.004*\"noise\" + 0.004*\"spike\" + 0.004*\"synaptic\"\n",
      "2025-04-01 14:03:08,109 : INFO : topic #3 (0.066): 0.004*\"approximation\" + 0.004*\"density\" + 0.003*\"gaussian\" + 0.003*\"matrix\" + 0.003*\"class\" + 0.003*\"sequence\" + 0.003*\"sample\" + 0.003*\"stochastic\" + 0.003*\"control\" + 0.003*\"dynamic\"\n",
      "2025-04-01 14:03:08,109 : INFO : topic #8 (0.069): 0.005*\"speech\" + 0.005*\"signal\" + 0.005*\"layer\" + 0.004*\"component\" + 0.004*\"recognition\" + 0.004*\"hidden\" + 0.004*\"image\" + 0.004*\"mixture\" + 0.004*\"noise\" + 0.003*\"class\"\n",
      "2025-04-01 14:03:08,109 : INFO : topic diff=0.255833, rho=0.500000\n",
      "2025-04-01 14:03:08,112 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2025-04-01 14:03:10,320 : INFO : optimized alpha [0.039132036, 0.051834542, 0.045849126, 0.0600012, 0.05181667, 0.05752318, 0.04892452, 0.03483365, 0.06134135, 0.04785946]\n",
      "2025-04-01 14:03:10,323 : INFO : topic #7 (0.035): 0.007*\"distance\" + 0.007*\"node\" + 0.006*\"graph\" + 0.005*\"robot\" + 0.005*\"tree\" + 0.004*\"tangent\" + 0.004*\"mapping\" + 0.003*\"matrix\" + 0.003*\"image\" + 0.003*\"parallel\"\n",
      "2025-04-01 14:03:10,323 : INFO : topic #0 (0.039): 0.010*\"action\" + 0.009*\"policy\" + 0.005*\"reinforcement\" + 0.005*\"optimal\" + 0.005*\"neuron\" + 0.004*\"reward\" + 0.004*\"reinforcement_learning\" + 0.004*\"control\" + 0.003*\"decision\" + 0.003*\"machine\"\n",
      "2025-04-01 14:03:10,324 : INFO : topic #5 (0.058): 0.016*\"neuron\" + 0.012*\"cell\" + 0.006*\"circuit\" + 0.006*\"signal\" + 0.005*\"response\" + 0.005*\"spike\" + 0.005*\"frequency\" + 0.004*\"synaptic\" + 0.004*\"chip\" + 0.004*\"noise\"\n",
      "2025-04-01 14:03:10,324 : INFO : topic #3 (0.060): 0.004*\"approximation\" + 0.004*\"gaussian\" + 0.004*\"density\" + 0.004*\"matrix\" + 0.003*\"stochastic\" + 0.003*\"sequence\" + 0.003*\"sample\" + 0.003*\"class\" + 0.003*\"prior\" + 0.003*\"bayesian\"\n",
      "2025-04-01 14:03:10,324 : INFO : topic #8 (0.061): 0.006*\"speech\" + 0.005*\"signal\" + 0.005*\"component\" + 0.005*\"mixture\" + 0.005*\"recognition\" + 0.004*\"layer\" + 0.004*\"hidden\" + 0.004*\"image\" + 0.004*\"word\" + 0.004*\"noise\"\n",
      "2025-04-01 14:03:10,325 : INFO : topic diff=0.232575, rho=0.447214\n",
      "2025-04-01 14:03:10,328 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2025-04-01 14:03:12,338 : INFO : optimized alpha [0.03652293, 0.049273543, 0.04338303, 0.05655199, 0.048746493, 0.055157557, 0.048054527, 0.033769492, 0.056352604, 0.045650158]\n",
      "2025-04-01 14:03:12,341 : INFO : topic #7 (0.034): 0.008*\"distance\" + 0.007*\"node\" + 0.006*\"graph\" + 0.005*\"robot\" + 0.004*\"tree\" + 0.004*\"tangent\" + 0.004*\"mapping\" + 0.003*\"matrix\" + 0.003*\"image\" + 0.003*\"parallel\"\n",
      "2025-04-01 14:03:12,342 : INFO : topic #0 (0.037): 0.012*\"action\" + 0.010*\"policy\" + 0.007*\"reinforcement\" + 0.005*\"optimal\" + 0.005*\"reinforcement_learning\" + 0.005*\"reward\" + 0.005*\"control\" + 0.004*\"decision\" + 0.003*\"neuron\" + 0.003*\"machine\"\n",
      "2025-04-01 14:03:12,342 : INFO : topic #5 (0.055): 0.017*\"neuron\" + 0.012*\"cell\" + 0.006*\"circuit\" + 0.006*\"signal\" + 0.005*\"spike\" + 0.005*\"response\" + 0.005*\"frequency\" + 0.005*\"synaptic\" + 0.004*\"chip\" + 0.004*\"firing\"\n",
      "2025-04-01 14:03:12,342 : INFO : topic #8 (0.056): 0.007*\"speech\" + 0.005*\"signal\" + 0.005*\"mixture\" + 0.005*\"component\" + 0.005*\"recognition\" + 0.004*\"word\" + 0.004*\"hidden\" + 0.004*\"layer\" + 0.004*\"image\" + 0.004*\"noise\"\n",
      "2025-04-01 14:03:12,343 : INFO : topic #3 (0.057): 0.005*\"gaussian\" + 0.005*\"approximation\" + 0.004*\"density\" + 0.004*\"matrix\" + 0.004*\"stochastic\" + 0.003*\"prior\" + 0.003*\"bayesian\" + 0.003*\"sample\" + 0.003*\"sequence\" + 0.003*\"noise\"\n",
      "2025-04-01 14:03:12,343 : INFO : topic diff=0.217450, rho=0.408248\n",
      "2025-04-01 14:03:12,346 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=8623, num_topics=10, decay=0.5, chunksize=2000> in 15.44s', 'datetime': '2025-04-01T14:03:12.346114', 'gensim': '4.3.3', 'python': '3.12.6 (v3.12.6:a4a2d2b0d85, Sep  6 2024, 16:08:03) [Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-15.3.2-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation time: 0.25741286675135294\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5knApWshObLO"
   },
   "source": "Let's see what we got. We are interested in part of the Phi matrix – the probabilities of words in topics. The NeurIPS collection is entirely dedicated to machine learning. It's difficult to evaluate the topics, though some interpretability can be traced."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJVQU_1rP2f2",
    "outputId": "a2e11a73-e3ff-4313-b926-7de2990f70fb",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:12.406163Z",
     "start_time": "2025-04-01T11:03:12.395189Z"
    }
   },
   "source": [
    "for position in range(10):\n",
    "    row = []\n",
    "    for topic in range(10):\n",
    "        row.append(model.show_topic(topic)[position][0].center(11, ' '))\n",
    "    print(''.join(row))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   action      node     gradient   gaussian    field      neuron     image     distance    speech      rule   \n",
      "   policy     bound   generalizationapproximation   visual      cell   recognition    node      signal     class   \n",
      "reinforcement   class     dynamic    density      cell     circuit     object     graph     mixture   prediction\n",
      "  optimal     hidden      net       matrix    stimulus    signal     layer      robot    component   control  \n",
      "reinforcement_learning    tree     minimum   stochastic   image      spike      hidden      tree   recognition classifier\n",
      "   reward   threshold     loss      prior      layer     response     face     tangent      word   classification\n",
      "  control    theorem    optimal    bayesian   response  frequency     net      mapping     hidden    estimate \n",
      "  decision     net      solution    sample     memory    synaptic  character    matrix     layer   training_set\n",
      "   neuron      let      teacher    sequence orientation    chip       view      image      image    validation\n",
      "  machine     layer     control     noise       map       firing  architecture  parallel    noise    regression\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLIuGnNpQpyP",
    "outputId": "8f33e7e4-9250-4898-cebe-db4e1a60c4ec",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:12.557704Z",
     "start_time": "2025-04-01T11:03:12.480784Z"
    }
   },
   "source": [
    "top_topics = model.top_topics(corpus)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:03:12,513 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQ-5eVhBQrsQ",
    "outputId": "8d47a367-ccf1-4569-be41-f7ec6c372d4a",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:12.626386Z",
     "start_time": "2025-04-01T11:03:12.623349Z"
    }
   },
   "source": [
    "top_topics[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.008333934, 'field'),\n",
       "  (0.007421196, 'visual'),\n",
       "  (0.0066706464, 'cell'),\n",
       "  (0.0065103243, 'stimulus'),\n",
       "  (0.005340202, 'image'),\n",
       "  (0.0052392543, 'layer'),\n",
       "  (0.0051620053, 'response'),\n",
       "  (0.0049079577, 'memory'),\n",
       "  (0.0046701324, 'orientation'),\n",
       "  (0.004652298, 'map'),\n",
       "  (0.0044042952, 'activity'),\n",
       "  (0.0042442977, 'cortex'),\n",
       "  (0.0037213287, 'receptive'),\n",
       "  (0.0034765801, 'location'),\n",
       "  (0.0034255898, 'receptive_field'),\n",
       "  (0.0033544719, 'connection'),\n",
       "  (0.0032896711, 'cortical'),\n",
       "  (0.0032853843, 'neuron'),\n",
       "  (0.0032728878, 'position'),\n",
       "  (0.0030441082, 'direction')],\n",
       " -0.9576207793821232)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-2vzw2RSGFA",
    "outputId": "b4f7c699-b384-430f-83c5-953fe591bf0f",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:20.310011Z",
     "start_time": "2025-04-01T11:03:20.306159Z"
    }
   },
   "source": [
    "model.inference([corpus[0]])[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9803188e+01, 6.7137939e+02, 4.3383028e-02, 5.6552000e-02,\n",
       "        4.8746493e-02, 1.0835744e+02, 4.8054527e-02, 3.3769492e-02,\n",
       "        5.6352612e-02, 4.5650158e-02]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X-HTzPGxs3F"
   },
   "source": [
    "### Perplexity evaluation\n",
    "We want to assess the model with something more convincing than just looking at topic profiles and document profiles. This is necessary for the possibility of comparing different models, for example, those obtained with different run parameters. Let's learn to measure **perplexity**. The function `model.state.get_lambda` returns the unnormalized $\\Phi$ matrix, and `model.inference` estimates the unnormalized $\\Theta$ matrix for a list of documents.\n",
    "\n",
    "We iterate through the collection and calculate perplexity using the formula. The lower the perplexity, the better."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8gVV_PFRxmIP",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:27.490779Z",
     "start_time": "2025-04-01T11:03:27.487809Z"
    }
   },
   "source": [
    "def perplexity(model, corpus):\n",
    "    corpus_length = 0\n",
    "    log_likelihood = 0\n",
    "    topic_profiles = model.state.get_lambda() / np.sum(model.state.get_lambda(), axis=1)[:, np.newaxis]\n",
    "    for document in corpus:\n",
    "        gamma, _ = model.inference([document])\n",
    "        document_profile = gamma / np.sum(gamma)\n",
    "        for term_id, term_count in document:\n",
    "            corpus_length += term_count\n",
    "            term_probability = np.dot(document_profile, topic_profiles[:, term_id])\n",
    "            log_likelihood += term_count * log(term_probability.item())\n",
    "    perplexity = np.exp(-log_likelihood / corpus_length)\n",
    "    return perplexity"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iN6amrvHTDKt",
    "outputId": "a268a642-2efd-4217-b899-cb3abeac1f31",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:03:33.847247Z",
     "start_time": "2025-04-01T11:03:31.597577Z"
    }
   },
   "source": [
    "print('Perplexity: {}'.format(perplexity(model, corpus)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2792.500048725142\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5_Sqil0TPYD",
    "outputId": "df2374d5-d768-4e5e-f741-15eb8ed0f0ea",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:04.189683Z",
     "start_time": "2025-04-01T11:03:33.854506Z"
    }
   },
   "source": [
    "model_5 = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=5,\n",
    "    passes=epochs,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "model_20 = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=20,\n",
    "    passes=epochs,\n",
    "    eval_every=eval_every\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:03:33,855 : INFO : using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "2025-04-01 14:03:33,856 : INFO : using serial LDA version on this node\n",
      "2025-04-01 14:03:33,857 : INFO : running online (multi-pass) LDA training, 5 topics, 5 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2025-04-01 14:03:33,858 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2025-04-01 14:03:33,858 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2025-04-01 14:03:38,722 : INFO : optimized alpha [0.10357928, 0.13110664, 0.22551106, 0.111403726, 0.15937737]\n",
      "2025-04-01 14:03:38,724 : INFO : topic #0 (0.104): 0.007*\"neuron\" + 0.005*\"memory\" + 0.004*\"layer\" + 0.004*\"cell\" + 0.003*\"hidden\" + 0.003*\"control\" + 0.003*\"signal\" + 0.003*\"net\" + 0.003*\"map\" + 0.003*\"circuit\"\n",
      "2025-04-01 14:03:38,724 : INFO : topic #1 (0.131): 0.003*\"matrix\" + 0.003*\"neuron\" + 0.003*\"component\" + 0.003*\"node\" + 0.003*\"object\" + 0.003*\"response\" + 0.003*\"solution\" + 0.003*\"field\" + 0.002*\"hidden\" + 0.002*\"prediction\"\n",
      "2025-04-01 14:03:38,725 : INFO : topic #2 (0.226): 0.003*\"neuron\" + 0.003*\"hidden\" + 0.003*\"noise\" + 0.003*\"matrix\" + 0.003*\"layer\" + 0.003*\"class\" + 0.003*\"recognition\" + 0.002*\"image\" + 0.002*\"dynamic\" + 0.002*\"signal\"\n",
      "2025-04-01 14:03:38,725 : INFO : topic #3 (0.111): 0.010*\"image\" + 0.004*\"class\" + 0.004*\"cell\" + 0.004*\"signal\" + 0.003*\"motion\" + 0.003*\"hidden\" + 0.003*\"node\" + 0.003*\"direction\" + 0.003*\"layer\" + 0.003*\"bound\"\n",
      "2025-04-01 14:03:38,725 : INFO : topic #4 (0.159): 0.007*\"neuron\" + 0.005*\"layer\" + 0.004*\"cell\" + 0.004*\"rule\" + 0.003*\"class\" + 0.003*\"control\" + 0.003*\"hidden\" + 0.002*\"word\" + 0.002*\"sequence\" + 0.002*\"node\"\n",
      "2025-04-01 14:03:38,725 : INFO : topic diff=1.050045, rho=1.000000\n",
      "2025-04-01 14:03:38,728 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2025-04-01 14:03:41,923 : INFO : optimized alpha [0.08467284, 0.09070903, 0.12522444, 0.08128987, 0.08352199]\n",
      "2025-04-01 14:03:41,925 : INFO : topic #0 (0.085): 0.010*\"neuron\" + 0.006*\"cell\" + 0.005*\"memory\" + 0.004*\"layer\" + 0.004*\"circuit\" + 0.004*\"control\" + 0.003*\"synaptic\" + 0.003*\"signal\" + 0.003*\"chip\" + 0.003*\"response\"\n",
      "2025-04-01 14:03:41,925 : INFO : topic #1 (0.091): 0.003*\"matrix\" + 0.003*\"component\" + 0.003*\"gaussian\" + 0.003*\"prediction\" + 0.003*\"solution\" + 0.003*\"object\" + 0.003*\"field\" + 0.003*\"node\" + 0.002*\"estimate\" + 0.002*\"stimulus\"\n",
      "2025-04-01 14:03:41,925 : INFO : topic #2 (0.125): 0.003*\"hidden\" + 0.003*\"matrix\" + 0.003*\"class\" + 0.003*\"noise\" + 0.003*\"recognition\" + 0.003*\"speech\" + 0.003*\"classifier\" + 0.003*\"dynamic\" + 0.002*\"layer\" + 0.002*\"sequence\"\n",
      "2025-04-01 14:03:41,926 : INFO : topic #3 (0.081): 0.012*\"image\" + 0.004*\"motion\" + 0.004*\"class\" + 0.004*\"cell\" + 0.003*\"signal\" + 0.003*\"direction\" + 0.003*\"object\" + 0.003*\"bound\" + 0.003*\"visual\" + 0.003*\"layer\"\n",
      "2025-04-01 14:03:41,926 : INFO : topic #4 (0.084): 0.007*\"neuron\" + 0.005*\"rule\" + 0.005*\"layer\" + 0.004*\"cell\" + 0.003*\"hidden\" + 0.003*\"word\" + 0.003*\"sequence\" + 0.003*\"node\" + 0.003*\"class\" + 0.003*\"control\"\n",
      "2025-04-01 14:03:41,926 : INFO : topic diff=0.184677, rho=0.577350\n",
      "2025-04-01 14:03:41,929 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2025-04-01 14:03:44,322 : INFO : optimized alpha [0.07518722, 0.07531345, 0.10686025, 0.06842091, 0.066634074]\n",
      "2025-04-01 14:03:44,324 : INFO : topic #0 (0.075): 0.011*\"neuron\" + 0.007*\"cell\" + 0.005*\"memory\" + 0.004*\"circuit\" + 0.004*\"layer\" + 0.004*\"control\" + 0.004*\"synaptic\" + 0.004*\"response\" + 0.004*\"signal\" + 0.003*\"connection\"\n",
      "2025-04-01 14:03:44,325 : INFO : topic #1 (0.075): 0.003*\"gaussian\" + 0.003*\"matrix\" + 0.003*\"prediction\" + 0.003*\"component\" + 0.003*\"solution\" + 0.003*\"node\" + 0.003*\"field\" + 0.003*\"estimate\" + 0.003*\"object\" + 0.002*\"noise\"\n",
      "2025-04-01 14:03:44,325 : INFO : topic #2 (0.107): 0.004*\"hidden\" + 0.003*\"matrix\" + 0.003*\"class\" + 0.003*\"speech\" + 0.003*\"classifier\" + 0.003*\"noise\" + 0.003*\"recognition\" + 0.003*\"sequence\" + 0.003*\"dynamic\" + 0.002*\"tree\"\n",
      "2025-04-01 14:03:44,325 : INFO : topic #3 (0.068): 0.014*\"image\" + 0.005*\"motion\" + 0.004*\"class\" + 0.004*\"object\" + 0.004*\"direction\" + 0.003*\"visual\" + 0.003*\"signal\" + 0.003*\"filter\" + 0.003*\"bound\" + 0.003*\"layer\"\n",
      "2025-04-01 14:03:44,325 : INFO : topic #4 (0.067): 0.006*\"rule\" + 0.006*\"neuron\" + 0.005*\"layer\" + 0.004*\"cell\" + 0.003*\"hidden\" + 0.003*\"word\" + 0.003*\"node\" + 0.003*\"sequence\" + 0.003*\"net\" + 0.003*\"recognition\"\n",
      "2025-04-01 14:03:44,326 : INFO : topic diff=0.152022, rho=0.500000\n",
      "2025-04-01 14:03:44,328 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2025-04-01 14:03:46,392 : INFO : optimized alpha [0.069842376, 0.06741594, 0.09722441, 0.06125754, 0.059413888]\n",
      "2025-04-01 14:03:46,394 : INFO : topic #0 (0.070): 0.012*\"neuron\" + 0.008*\"cell\" + 0.004*\"memory\" + 0.004*\"circuit\" + 0.004*\"response\" + 0.004*\"control\" + 0.004*\"synaptic\" + 0.004*\"layer\" + 0.004*\"signal\" + 0.004*\"connection\"\n",
      "2025-04-01 14:03:46,394 : INFO : topic #1 (0.067): 0.004*\"gaussian\" + 0.003*\"matrix\" + 0.003*\"prediction\" + 0.003*\"solution\" + 0.003*\"component\" + 0.003*\"estimate\" + 0.003*\"node\" + 0.003*\"field\" + 0.003*\"noise\" + 0.003*\"mixture\"\n",
      "2025-04-01 14:03:46,395 : INFO : topic #2 (0.097): 0.004*\"hidden\" + 0.003*\"class\" + 0.003*\"matrix\" + 0.003*\"speech\" + 0.003*\"classifier\" + 0.003*\"recognition\" + 0.003*\"noise\" + 0.003*\"sequence\" + 0.003*\"tree\" + 0.003*\"optimal\"\n",
      "2025-04-01 14:03:46,395 : INFO : topic #3 (0.061): 0.016*\"image\" + 0.005*\"motion\" + 0.005*\"object\" + 0.004*\"class\" + 0.004*\"visual\" + 0.004*\"direction\" + 0.004*\"filter\" + 0.004*\"layer\" + 0.003*\"signal\" + 0.003*\"bound\"\n",
      "2025-04-01 14:03:46,395 : INFO : topic #4 (0.059): 0.006*\"rule\" + 0.005*\"layer\" + 0.005*\"neuron\" + 0.004*\"hidden\" + 0.004*\"word\" + 0.003*\"node\" + 0.003*\"net\" + 0.003*\"sequence\" + 0.003*\"recognition\" + 0.003*\"activation\"\n",
      "2025-04-01 14:03:46,395 : INFO : topic diff=0.130053, rho=0.447214\n",
      "2025-04-01 14:03:46,398 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2025-04-01 14:03:48,211 : INFO : optimized alpha [0.0664629, 0.06290867, 0.09066472, 0.05713148, 0.056016937]\n",
      "2025-04-01 14:03:48,212 : INFO : topic #0 (0.066): 0.013*\"neuron\" + 0.009*\"cell\" + 0.005*\"response\" + 0.005*\"circuit\" + 0.004*\"memory\" + 0.004*\"signal\" + 0.004*\"synaptic\" + 0.004*\"activity\" + 0.004*\"control\" + 0.004*\"connection\"\n",
      "2025-04-01 14:03:48,213 : INFO : topic #1 (0.063): 0.004*\"gaussian\" + 0.003*\"matrix\" + 0.003*\"prediction\" + 0.003*\"solution\" + 0.003*\"component\" + 0.003*\"estimate\" + 0.003*\"mixture\" + 0.003*\"variance\" + 0.003*\"noise\" + 0.003*\"density\"\n",
      "2025-04-01 14:03:48,213 : INFO : topic #2 (0.091): 0.004*\"hidden\" + 0.004*\"class\" + 0.003*\"matrix\" + 0.003*\"classifier\" + 0.003*\"speech\" + 0.003*\"optimal\" + 0.003*\"tree\" + 0.003*\"recognition\" + 0.003*\"sequence\" + 0.003*\"dynamic\"\n",
      "2025-04-01 14:03:48,213 : INFO : topic #3 (0.057): 0.017*\"image\" + 0.005*\"object\" + 0.005*\"motion\" + 0.004*\"visual\" + 0.004*\"class\" + 0.004*\"filter\" + 0.004*\"direction\" + 0.004*\"layer\" + 0.004*\"recognition\" + 0.004*\"pixel\"\n",
      "2025-04-01 14:03:48,214 : INFO : topic #4 (0.056): 0.006*\"rule\" + 0.005*\"layer\" + 0.005*\"hidden\" + 0.004*\"net\" + 0.004*\"word\" + 0.004*\"neuron\" + 0.003*\"node\" + 0.003*\"sequence\" + 0.003*\"recognition\" + 0.003*\"activation\"\n",
      "2025-04-01 14:03:48,214 : INFO : topic diff=0.114561, rho=0.408248\n",
      "2025-04-01 14:03:48,216 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=8623, num_topics=5, decay=0.5, chunksize=2000> in 14.36s', 'datetime': '2025-04-01T14:03:48.216693', 'gensim': '4.3.3', 'python': '3.12.6 (v3.12.6:a4a2d2b0d85, Sep  6 2024, 16:08:03) [Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-15.3.2-arm64-arm-64bit', 'event': 'created'}\n",
      "2025-04-01 14:03:48,217 : INFO : using autotuned alpha, starting with [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
      "2025-04-01 14:03:48,217 : INFO : using serial LDA version on this node\n",
      "2025-04-01 14:03:48,223 : INFO : running online (multi-pass) LDA training, 20 topics, 5 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2025-04-01 14:03:48,223 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2025-04-01 14:03:48,224 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2025-04-01 14:04:20,346 : INFO : optimized alpha [0.046191677, 0.04763756, 0.044535566, 0.0354661, 0.038895965, 0.040408887, 0.050305426, 0.035685133, 0.036848318, 0.042964898, 0.040267386, 0.045841176, 0.046599146, 0.046095315, 0.04275865, 0.04521833, 0.038213097, 0.041832574, 0.03806594, 0.050925143]\n",
      "2025-04-01 14:04:20,364 : INFO : topic #3 (0.035): 0.005*\"tree\" + 0.005*\"matrix\" + 0.004*\"dynamic\" + 0.004*\"query\" + 0.003*\"let\" + 0.003*\"component\" + 0.003*\"hidden\" + 0.003*\"graph\" + 0.003*\"net\" + 0.003*\"memory\"\n",
      "2025-04-01 14:04:20,371 : INFO : topic #7 (0.036): 0.007*\"visual\" + 0.006*\"orientation\" + 0.005*\"response\" + 0.005*\"threshold\" + 0.004*\"fig\" + 0.004*\"cell\" + 0.004*\"signal\" + 0.004*\"object\" + 0.004*\"activity\" + 0.004*\"element\"\n",
      "2025-04-01 14:04:20,373 : INFO : topic #1 (0.048): 0.006*\"cell\" + 0.005*\"neuron\" + 0.005*\"field\" + 0.005*\"image\" + 0.004*\"rule\" + 0.004*\"recognition\" + 0.003*\"visual\" + 0.003*\"face\" + 0.003*\"class\" + 0.003*\"signal\"\n",
      "2025-04-01 14:04:20,383 : INFO : topic #6 (0.050): 0.005*\"layer\" + 0.005*\"classifier\" + 0.004*\"neuron\" + 0.004*\"class\" + 0.004*\"node\" + 0.003*\"cell\" + 0.003*\"hidden\" + 0.003*\"signal\" + 0.003*\"sequence\" + 0.003*\"classification\"\n",
      "2025-04-01 14:04:20,386 : INFO : topic #19 (0.051): 0.006*\"image\" + 0.006*\"noise\" + 0.005*\"neuron\" + 0.004*\"node\" + 0.003*\"position\" + 0.003*\"layer\" + 0.003*\"class\" + 0.003*\"matrix\" + 0.003*\"hidden\" + 0.003*\"distance\"\n",
      "2025-04-01 14:04:20,386 : INFO : topic diff=1.805547, rho=1.000000\n",
      "2025-04-01 14:04:20,396 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2025-04-01 14:04:33,949 : INFO : optimized alpha [0.04110548, 0.04106822, 0.042611156, 0.03112449, 0.034540534, 0.0373636, 0.044420157, 0.03206929, 0.031620968, 0.037215494, 0.03643569, 0.04052671, 0.042521555, 0.04385684, 0.03843299, 0.041747674, 0.035058595, 0.037182055, 0.033292517, 0.044211254]\n",
      "2025-04-01 14:04:33,961 : INFO : topic #3 (0.031): 0.009*\"tree\" + 0.007*\"matrix\" + 0.005*\"graph\" + 0.005*\"query\" + 0.005*\"dynamic\" + 0.004*\"let\" + 0.004*\"component\" + 0.003*\"theorem\" + 0.003*\"memory\" + 0.003*\"net\"\n",
      "2025-04-01 14:04:33,970 : INFO : topic #8 (0.032): 0.005*\"neuron\" + 0.004*\"hint\" + 0.004*\"tree\" + 0.004*\"synaptic\" + 0.004*\"node\" + 0.004*\"class\" + 0.004*\"rule\" + 0.003*\"optimal\" + 0.003*\"cost\" + 0.003*\"response\"\n",
      "2025-04-01 14:04:33,980 : INFO : topic #13 (0.044): 0.005*\"class\" + 0.003*\"density\" + 0.003*\"machine\" + 0.003*\"sample\" + 0.003*\"kernel\" + 0.003*\"regression\" + 0.003*\"hidden\" + 0.003*\"approximation\" + 0.003*\"optimal\" + 0.003*\"bound\"\n",
      "2025-04-01 14:04:33,994 : INFO : topic #19 (0.044): 0.008*\"image\" + 0.007*\"noise\" + 0.005*\"neuron\" + 0.004*\"node\" + 0.004*\"position\" + 0.003*\"distance\" + 0.003*\"spike\" + 0.003*\"object\" + 0.003*\"layer\" + 0.003*\"matrix\"\n",
      "2025-04-01 14:04:34,005 : INFO : topic #6 (0.044): 0.008*\"classifier\" + 0.006*\"layer\" + 0.005*\"class\" + 0.005*\"node\" + 0.004*\"classification\" + 0.003*\"hidden\" + 0.003*\"sequence\" + 0.003*\"rule\" + 0.003*\"neuron\" + 0.003*\"region\"\n",
      "2025-04-01 14:04:34,014 : INFO : topic diff=0.545003, rho=0.577350\n",
      "2025-04-01 14:04:34,021 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2025-04-01 14:04:46,387 : INFO : optimized alpha [0.03770669, 0.036993768, 0.041834507, 0.028741848, 0.031842973, 0.035371214, 0.040251892, 0.02988803, 0.028412784, 0.033507213, 0.034523793, 0.0370958, 0.040102188, 0.04215292, 0.035770725, 0.040263645, 0.033583455, 0.03435309, 0.030527579, 0.03908943]\n",
      "2025-04-01 14:04:46,401 : INFO : topic #8 (0.028): 0.006*\"hint\" + 0.004*\"rule\" + 0.004*\"synaptic\" + 0.004*\"neuron\" + 0.004*\"genetic\" + 0.004*\"tree\" + 0.004*\"node\" + 0.004*\"cost\" + 0.004*\"optimal\" + 0.004*\"class\"\n",
      "2025-04-01 14:04:46,413 : INFO : topic #3 (0.029): 0.013*\"tree\" + 0.008*\"matrix\" + 0.007*\"graph\" + 0.006*\"query\" + 0.005*\"dynamic\" + 0.005*\"let\" + 0.004*\"component\" + 0.004*\"node\" + 0.004*\"memory\" + 0.004*\"theorem\"\n",
      "2025-04-01 14:04:46,422 : INFO : topic #15 (0.040): 0.007*\"bound\" + 0.005*\"approximation\" + 0.004*\"theorem\" + 0.004*\"let\" + 0.004*\"solution\" + 0.004*\"dimension\" + 0.004*\"layer\" + 0.003*\"matrix\" + 0.003*\"net\" + 0.003*\"class\"\n",
      "2025-04-01 14:04:46,426 : INFO : topic #2 (0.042): 0.007*\"hidden\" + 0.007*\"action\" + 0.005*\"optimal\" + 0.005*\"gradient\" + 0.005*\"control\" + 0.004*\"hidden_unit\" + 0.004*\"policy\" + 0.004*\"reinforcement\" + 0.004*\"prediction\" + 0.004*\"convergence\"\n",
      "2025-04-01 14:04:46,427 : INFO : topic #13 (0.042): 0.005*\"class\" + 0.004*\"kernel\" + 0.004*\"machine\" + 0.004*\"regression\" + 0.004*\"sample\" + 0.003*\"density\" + 0.003*\"approximation\" + 0.003*\"hidden\" + 0.003*\"optimal\" + 0.003*\"bound\"\n",
      "2025-04-01 14:04:46,428 : INFO : topic diff=0.534580, rho=0.500000\n",
      "2025-04-01 14:04:46,434 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2025-04-01 14:04:57,289 : INFO : optimized alpha [0.035315327, 0.034514826, 0.04145922, 0.027272956, 0.030140042, 0.033956826, 0.03769, 0.028366836, 0.026178034, 0.031070337, 0.033173356, 0.034944847, 0.038411777, 0.040847663, 0.034022443, 0.03977339, 0.032900862, 0.032514423, 0.028714538, 0.035362344]\n",
      "2025-04-01 14:04:57,301 : INFO : topic #8 (0.026): 0.007*\"hint\" + 0.006*\"genetic\" + 0.005*\"rule\" + 0.005*\"memory\" + 0.004*\"synaptic\" + 0.004*\"cost\" + 0.004*\"genetic_algorithm\" + 0.004*\"node\" + 0.004*\"optimal\" + 0.004*\"skill\"\n",
      "2025-04-01 14:04:57,306 : INFO : topic #3 (0.027): 0.016*\"tree\" + 0.008*\"graph\" + 0.008*\"matrix\" + 0.006*\"query\" + 0.006*\"node\" + 0.005*\"dynamic\" + 0.005*\"let\" + 0.004*\"component\" + 0.004*\"memory\" + 0.004*\"theorem\"\n",
      "2025-04-01 14:04:57,312 : INFO : topic #15 (0.040): 0.008*\"bound\" + 0.006*\"approximation\" + 0.005*\"theorem\" + 0.005*\"let\" + 0.004*\"dimension\" + 0.004*\"solution\" + 0.004*\"layer\" + 0.004*\"class\" + 0.004*\"net\" + 0.003*\"matrix\"\n",
      "2025-04-01 14:04:57,315 : INFO : topic #13 (0.041): 0.005*\"class\" + 0.005*\"kernel\" + 0.004*\"regression\" + 0.004*\"sample\" + 0.004*\"machine\" + 0.003*\"approximation\" + 0.003*\"density\" + 0.003*\"bayesian\" + 0.003*\"xi\" + 0.003*\"estimate\"\n",
      "2025-04-01 14:04:57,327 : INFO : topic #2 (0.041): 0.008*\"action\" + 0.007*\"hidden\" + 0.005*\"policy\" + 0.005*\"control\" + 0.005*\"optimal\" + 0.005*\"reinforcement\" + 0.005*\"gradient\" + 0.004*\"hidden_unit\" + 0.004*\"dynamic\" + 0.003*\"convergence\"\n",
      "2025-04-01 14:04:57,339 : INFO : topic diff=0.530782, rho=0.447214\n",
      "2025-04-01 14:04:57,364 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2025-04-01 14:05:04,118 : INFO : optimized alpha [0.033763647, 0.032978266, 0.041190658, 0.026262479, 0.028890084, 0.03290762, 0.036117345, 0.027240487, 0.024548285, 0.029292818, 0.032141272, 0.03347765, 0.03726692, 0.039881326, 0.03275729, 0.039813504, 0.032681104, 0.031314068, 0.02749911, 0.032686874]\n",
      "2025-04-01 14:05:04,125 : INFO : topic #8 (0.025): 0.008*\"hint\" + 0.007*\"genetic\" + 0.006*\"rule\" + 0.005*\"memory\" + 0.005*\"genetic_algorithm\" + 0.004*\"population\" + 0.004*\"cost\" + 0.004*\"optimal\" + 0.004*\"skill\" + 0.004*\"synaptic\"\n",
      "2025-04-01 14:05:04,126 : INFO : topic #3 (0.026): 0.019*\"tree\" + 0.009*\"graph\" + 0.008*\"matrix\" + 0.007*\"node\" + 0.006*\"query\" + 0.005*\"dynamic\" + 0.005*\"memory\" + 0.005*\"let\" + 0.005*\"component\" + 0.004*\"theorem\"\n",
      "2025-04-01 14:05:04,128 : INFO : topic #15 (0.040): 0.008*\"bound\" + 0.006*\"approximation\" + 0.005*\"theorem\" + 0.005*\"let\" + 0.004*\"dimension\" + 0.004*\"solution\" + 0.004*\"layer\" + 0.004*\"class\" + 0.004*\"net\" + 0.003*\"generalization\"\n",
      "2025-04-01 14:05:04,140 : INFO : topic #13 (0.040): 0.005*\"class\" + 0.005*\"kernel\" + 0.004*\"regression\" + 0.004*\"sample\" + 0.004*\"machine\" + 0.004*\"bayesian\" + 0.004*\"approximation\" + 0.003*\"estimate\" + 0.003*\"xi\" + 0.003*\"density\"\n",
      "2025-04-01 14:05:04,142 : INFO : topic #2 (0.041): 0.008*\"action\" + 0.007*\"hidden\" + 0.006*\"policy\" + 0.005*\"control\" + 0.005*\"reinforcement\" + 0.005*\"optimal\" + 0.004*\"gradient\" + 0.004*\"hidden_unit\" + 0.004*\"dynamic\" + 0.003*\"reinforcement_learning\"\n",
      "2025-04-01 14:05:04,144 : INFO : topic diff=0.524717, rho=0.408248\n",
      "2025-04-01 14:05:04,170 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=8623, num_topics=20, decay=0.5, chunksize=2000> in 75.95s', 'datetime': '2025-04-01T14:05:04.170303', 'gensim': '4.3.3', 'python': '3.12.6 (v3.12.6:a4a2d2b0d85, Sep  6 2024, 16:08:03) [Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-15.3.2-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYR1kXEFTWMg",
    "outputId": "2463aa3f-b0d7-4980-dcdf-43e7f62e41c7",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:12.473343Z",
     "start_time": "2025-04-01T11:05:04.217694Z"
    }
   },
   "source": [
    "print('Perplexity 5: {}'.format(perplexity(model_5, corpus)))\n",
    "print('Perplexity 20: {}'.format(perplexity(model_20, corpus)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity 5: 3121.8680595351993\n",
      "Perplexity 20: 2518.910892162995\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5yh-RhCxwcT"
   },
   "source": [
    "### Word2Vec model\n",
    "Word2Vec is one of the fundamental neural network models of the \"pre-transformer\" era (2013-2018). The essence of the model is to build a mapping of words into an $N$-dimensional space (embeddings) with certain characteristics. Two words have more similar embeddings the more similar the contexts in which they are used.\n",
    "\n",
    "In the `gensim` library, two methods for building word2vec are implemented:\n",
    "  - Skip-grams (SG)\n",
    "  - Continuous-bag-of-words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYtz7rDrVyKS"
   },
   "source": [
    "## Demo\n",
    "For the demonstration, let's take a pre-trained model trained on the Google News dataset, containing approximately 3 million English words and phrases."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTcMvyG1V1wH",
    "outputId": "e1aac14d-a61b-4876-84e4-7a751e10ddaf",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:32.569455Z",
     "start_time": "2025-04-01T11:05:19.697613Z"
    }
   },
   "source": [
    "# download the model ~1.6GB \n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:05:19,983 : INFO : loading projection weights from /Users/Aleksandr.Avdiushenko/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2025-04-01 14:05:32,568 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/Aleksandr.Avdiushenko/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-04-01T14:05:32.568123', 'gensim': '4.3.3', 'python': '3.12.6 (v3.12.6:a4a2d2b0d85, Sep  6 2024, 16:08:03) [Clang 13.0.0 (clang-1300.0.29.30)]', 'platform': 'macOS-15.3.2-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gUr1QvQWCg_",
    "outputId": "5fdde298-1dfe-4067-b132-b95e91e7c6da",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:34.618863Z",
     "start_time": "2025-04-01T11:05:34.616474Z"
    }
   },
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key )} is {word}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewckl1qAX7Cp",
    "outputId": "f7c5715c-3273-4933-f98b-ba68ca0616fd",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:36.479179Z",
     "start_time": "2025-04-01T11:05:36.476819Z"
    }
   },
   "source": [
    "vec_king = wv['king']\n",
    "print(vec_king[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
      "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the model, you can compute the distances between words."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "359E_KR7YcQG",
    "outputId": "1cfcd100-166f-4efe-94aa-f7a0c0c21817",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:41.535968Z",
     "start_time": "2025-04-01T11:05:41.533024Z"
    }
   },
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofdJmw4mYqKz"
   },
   "source": "You can also find the most similar words to a given one."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "OJ1Gj7JMYtvp",
    "outputId": "c4ebce20-8cb3-41cb-bcc4-0cc2617b037d",
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:44.803751Z",
     "start_time": "2025-04-01T11:05:43.750907Z"
    }
   },
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532192707061768), ('vehicle', 0.8175783753395081), ('pickup_truck', 0.7763689756393433), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565719485282898)]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:45.939490Z",
     "start_time": "2025-04-01T11:05:45.860490Z"
    }
   },
   "source": [
    "vec_example = wv['king'] - wv['man'] + wv['woman']\n",
    "\n",
    "similars = wv.most_similar(positive=[vec_example])\n",
    "print(similars)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('king', 0.8449392318725586), ('queen', 0.7300516366958618), ('monarch', 0.6454660296440125), ('princess', 0.6156251430511475), ('crown_prince', 0.5818676948547363), ('prince', 0.5777117609977722), ('kings', 0.5613663792610168), ('sultan', 0.5376776456832886), ('Queen_Consort', 0.5344247817993164), ('queens', 0.5289887189865112)]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:05:47.920433Z",
     "start_time": "2025-04-01T11:05:47.864410Z"
    }
   },
   "source": [
    "vec_example = wv['programmer'] - wv['man'] + wv['woman'] \n",
    "\n",
    "similars = wv.most_similar(positive=[vec_example])\n",
    "print(similars)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('programmer', 0.885962188243866), ('programmers', 0.6040860414505005), ('computer_programmer', 0.5623369216918945), ('coder', 0.5616979598999023), ('Programmer', 0.5576066374778748), ('programer', 0.5161396265029907), ('graphic_designer', 0.5139066576957703), ('coders', 0.48765403032302856), ('designer', 0.4822673797607422), ('librarian', 0.4649229943752289)]\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
