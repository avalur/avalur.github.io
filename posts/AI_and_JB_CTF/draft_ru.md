Сегодня хочу поделиться опытом своего первого в жизни участия в CTF соревновании. Сразу скажу, что такая возможность у меня появилась исключительно благодаря разрешению использовать ИИ, ну и, конечно, сообразительности фронтирных моделей.

![first_time_mem](first_time_mem.png)

## Введение
Вообще соревнования с использованием компьютера можно разбить на три группы. Кроме киберспорта, в котором я совсем мало что понимаю, и там всё сильно зависит от конкретной игры, есть ещё
 1. спортивное программирование: в финале ICPC команды из 3 человек решают 12 алгоритмических задач в течение 5 часов - нужно написать код, который выдаст правильные ответы на тестах в рамках заданных ограничений по времени и памяти. Обычно там вариации на тему зубодробительных алгоритмов, типа суффиксного дерева какого-нибудь. Ещё этот тип соревнований ближе всего к классическим олимпиадам по математике, поэтому довольно часто сильные студенты переквалифицируются из математиков в спортивных программистов.
 2. соревнования по машинному обучению - здесь главный ориентир это https://www.kaggle.com/, где компании приносят данные и задачу на несколько месяцев, в которой обычно нужно добиться максимального значения по заданной метрике, иногда ещё есть ограничения на время и используемые при обучении и инференсе моделей вычислительные ресурсы.
3. кибербезопасность: здесь тоже есть International CyberSecurity Challenge, командный чемпионат стран, и ещё престижный DEF CON CTF (Capture The Flag), в котором команды "хакеров" защищают свои флаги и пишут атаки для похищения флагов других команд.

При этом в ICPC использование ИИ запрещено правилами, что вполне понятно - этим летом GPT-5 уже успешно решила все 12 задач, в то время как лучшая команда людей смогли сдать 11.
В машинном обучении, конечно, активно используются модели, но для долгих многодневных соревнований это пока менее актуально, так как люди тоже всё ещё довольно хорошо справляются.

Что же в соревнованиях по кибербезопасности? Как обычно, решил проверить это на собственном опыте и поучаствовать во внутреннем чемпионате компании JetBrains. Честно повторю, что это был первый такой мой опыт в жизни, и до этого я никогда не интересовался кибербезопасностью, только математикой и машинным обучением.

![hacker_newbee](hacker_newbee.png)

## Мой сетап и первые результаты
Понятно, что никаким кибербезопасником за несколько дней не станешь.

![first_day_cybersec](first_day_cybersec.png)

Поэтому одной из главных моих целей была проверка Claude Code + Opus 4.5 и других моделей на интересных и сложных задачах кибербезопасности. При этом такие задачи кажутся довольно естественной средой для кодового агента - нужно писать скрипты, отправлять запросы по сети, анализировать ответы и подмечать странности, из которых уже получать уязвимости и использовать их. Как впоследствии оказалось, было важно, что у меня был безлимитный Claude Code =)
Он проявил себя очень и очень хорошо! Практически все решения нашел именно он, вот график нашего прогресса, см. оранжевого AlexA:
![comp_progress](./comp_progress.png)

Поначалу я просто запустил четыре параллельных экземпляра Claude Code + Opus 4.5 в терминале iTerm, чтобы они могли  решать задачи быстрее. В итоге, за первые 4 часа мы с ним решили уже 16 из 31 задачи с первого промпта, что было очень хорошим результатом, и даже давало уверенное первое место на лидерборде =)

![temporary_first_place](./temporary_first_place.jpg)

После такого старта уже сложно было остановиться, и на следующий день мы с Клодом продолжили и сделали ещё задач 10, а те, которые он не смог, решила Junie и потом ещё пару-тройку Codex агент с моделью gpt-5.2-codex и максимальными лимитами, который как раз во время на второй день соревнований появился в Пайчарме =) 

В общем на выходные оставалось решить только две задачи уровня "Hard" - одна по взламыванию системы из нескольких ИИ-чат-ботов, а вторая про небезопасный доступ к памяти из Java-приложения. Они совсем не поддавались - даже пятичасовые сессии в терминале не давали никакого результата и зацикливались.

Поскольку я немного знаю машинное обучение, решил сначала вписаться в обход защит ИИ-чат-ботов, максимально направляя Claude Code, какие именно варианты и уязвимости могут быть в принципе. Самое забавное, что флаг в итоге нашел Codex, который просто сам себе работал и, нашел решение. 

![two_buttons_meme](two_buttons_meme.jpg)

Как обычно, когда уже знаешь, то решение кажется простым и очевидным.
ИИ-валидатор просто обнаруживал запрещенные подстроки в прямых выходных данных. Поэтому если запрашивать шестнадцатеричные байты, то модель никогда не выдает запрещенную строку в неизменном виде, поэтому валидатор разрешает ответ. Таким образом мы можем расшифровать ее локально и восстановить флаг!

После этого я ещё раз отметил для себя, что нужны разные модели (хотя иногда и просто перезапуск Claude Code тоже помогал) и сразу пошел оплатить себе токен для Gemini 3 - по [своим летним экспериментам](https://avalur.github.io/posts/AlphaGoMomentForMaths.html) с олимпиадными задачами по математике я знал, что она хороша.

## Заключительные мысли
 - На самом деле очень весело направлять очень умную модель в области, в которой ты сам почти ничего не понимаешь - а соревновательный эффект заставляет не останавливаться! Не помню уже даже, когда я также засиживался до поздней ночи, чтобы попробовать решить все таски =)
 - Пока что это совсем не дешевое удовольствие - на оплату токенов Claude Code ушло около 2000$, ещё 50$ на Gemini 3, ну и около 300$ на Codex. Понятно, что в будущем токены будут дешевле, а модели ещё умнее.
 - Интересно наблюдать за работой агентов - они безустанно делают всё, чтобы добиться поставленной цели и при этом максимально стараются учесть твой промпт
 - они по-прежнему не всемогущи, могут зациклиться и бесконечно ходить по кругу. Похоже ещё есть даже такие чётко поставленные CTF-задачи, которые агенты не могут решить за день-два!





